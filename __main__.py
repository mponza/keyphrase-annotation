import os
import logging
import baker

from dataset import make_dataset

from annotation import tagme_annotation
from relatedness import tagme_relatedness

from utils.directory import DATASET_DIRS


logger = logging.getLogger(__name__)


@baker.command
def annotate(dataset_name, output_dir, threads=None):
    """
    Annotates a dataset and save annotations into output_dir.
    """
    logger.info('Running annotation over {0}...'.format(dataset_name))

    dataset = make_dataset(dataset_name)
    tagme_annotation(dataset, output_dir, threads)

    logger.info('Annotation for dataset {} ended.'.format(dataset_name))


@baker.command
def annotate_all(main_output_dir):
	"""
    Annotates all dataset and save outputs into main_output_dir.
    """
	for dataset_name, dir_name in DATASET_DIRS.items():
		output_dir = os.path.join(main_output_dir, dir_name)
		annotate(dataset_name, output_dir)


@baker.command
def relatedness(data_dir, output_dir):
    logger.info('Computing Relatedness for entity pairs of dataset {0}'.format(data_dir))
    tagme_relatedness(data_dir, output_dir)


@baker.command
def relatedness_all(datasets_dir, output_dir):
    """
    Enhances the annotations generated by annotate_all with the relatedness
    between pairs of entities of each document.

    @dataset_dir    annotated keyphrase datasets (main_output_dir of annotate_all)
    @output_dir     keyphrase dataset dir enhanced with the relatedness between entity pairs
    """
    for dataset_name, dir_name in DATASET_DIRS.items():
        data_dir = os.path.join(datasets_dir, dir_name)
        out_data_dir = os.path.join(output_dir, dir_name)

        relatedness(data_dir, out_data_dir)


if __name__ == '__main__':
    logging.basicConfig(format="%(asctime)-15s %(message)s",level=logging.INFO,datefmt='%Y-%m-%d %H:%M:%S')
    baker.run()
